{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "class EKFAC(torch.optim.Optimizer):\n",
    "    \"\"\" Implements the Eigenvalue-corrected Kronecker-factored Optimized Curvature preconditioner \n",
    "    \n",
    "    See details at https://arxiv.org/pdf/1806.03884.pdf\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 network, \n",
    "                 recompute_KFAC_steps=10,\n",
    "                 epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            network - the network to operate on\n",
    "            recompute_KFAC_steps (integer) - the number of steps between successive recomputations of the \n",
    "                                             Kronecker factors of the layer-wise Fisher matrix\n",
    "            epsilon (float) - the damping parameter used to avoid infinities\"\"\"\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.params_by_layer = []\n",
    "        \n",
    "        self.modules_with_weights = [torch.nn.Bilinear, \n",
    "                        torch.nn.Conv1d,\n",
    "                        torch.nn.Conv2d,\n",
    "                        torch.nn.Conv3d,\n",
    "                        torch.nn.ConvTranspose1d,\n",
    "                        torch.nn.ConvTranspose2d,\n",
    "                        torch.nn.ConvTranspose3d,\n",
    "                        torch.nn.Linear,                        \n",
    "                       ]\n",
    "        \n",
    "        self.stored_items = {}\n",
    "        \n",
    "        # need to keep track of iteration because we only recompute KFAC matrices every 'self.recompute_KFAC_steps' steps \n",
    "        self.iteration_number = 0 \n",
    "        self.recompute_KFAC_steps = recompute_KFAC_steps\n",
    "        \n",
    "        tracked_modules_count = 0\n",
    "        for layer in network.modules():\n",
    "            if type(layer) in self.modules_with_weights: \n",
    "                if type(layer) != torch.nn.Linear:\n",
    "                    warnings.warn('Have not tested this for any module type other than linear')\n",
    "                    \n",
    "                # add functions to the module such that for all layers with weights\n",
    "                layer.register_forward_pre_hook(self.store_input)\n",
    "                layer.register_backward_hook(self.store_grad_output)\n",
    "                \n",
    "                # add parameters to the list, grouped by layer \n",
    "                self.params_by_layer.append({'params': [layer.weight]})\n",
    "                if layer.bias is not None:\n",
    "                    self.params_by_layer[-1]['params'].append(layer.bias)\n",
    "        \n",
    "                # make a label for the module and add it to the keys of the stored_items dictionary\n",
    "                tracked_modules_count += 1\n",
    "                self.stored_items[layer] = {} \n",
    "                \n",
    "        default_options = {}\n",
    "        super(EKFAC, self).__init__(self.params_by_layer, default_options)\n",
    "       \n",
    "    def step(self):\n",
    "        \n",
    "        if self.iteration_number % self.recompute_KFAC_steps == 0:\n",
    "            self.compute_Kronecker_matrices()\n",
    "            \n",
    "        self.compute_scalings()\n",
    "        self.precondition()\n",
    "        \n",
    "        self.iteration_number += 1\n",
    "        \n",
    "    def store_input(self, module, inputs_to_module):\n",
    "        \"\"\" When called before running each layer with weights, this function stores\n",
    "        the input to the layer\"\"\"\n",
    "        \n",
    "        self.stored_items[module]['input'] = inputs_to_module[0].t()\n",
    "    \n",
    "    def store_grad_output(self, module, grad_wrt_input, grad_wrt_output):\n",
    "        \"\"\" When called after the backward pass of each layer with weights, this function\n",
    "        stores the gradient of the backwards-running function (usually the loss function) with respect\n",
    "        to the pre-activations, i.e. the output of the layer\"\"\"\n",
    "        \n",
    "        self.stored_items[module]['grad_wrt_output'] = grad_wrt_output[0]\n",
    "\n",
    "    def compute_Kronecker_matrices(self):\n",
    "        \"\"\" For each layer (or, more properly, parameter group), computes the Kronecker-factored matrices, \n",
    "        where the Kronecker factors are defined by \n",
    "        A = E[input_to_layer @ input_to_layer.T]\n",
    "        B = E[grad_wrt_output @ grad_wrt_output.T]\n",
    "        \"\"\"\n",
    "        \n",
    "        for layer, stored_values in self.stored_items.items():\n",
    "            # notation follows the EKFAC paper\n",
    "            h = stored_values['input']\n",
    "            delta = stored_values['grad_wrt_output']\n",
    "            \n",
    "            # We want E[ h @ h.T]\n",
    "            # h should always be of size (n_inputs, batch_size)\n",
    "            # delta should be of size (batch_size, n_outputs)\n",
    "            with torch.no_grad():\n",
    "                A = h @ h.transpose(1,0) / h.shape[1]\n",
    "                B = delta.transpose(1,0) @ delta / delta.shape[0]\n",
    "            \n",
    "            # Eigendecompose A and B to get UA and UB, which contain the eigenvectors\n",
    "            # UA @ diag(EvalsA) @ UA.t() = A\n",
    "            EvalsA, UA = torch.symeig(A, eigenvectors=True)\n",
    "            EvalsB, UB = torch.symeig(B, eigenvectors=True)\n",
    "            \n",
    "            self.stored_items[layer]['UA'] = UA\n",
    "            self.stored_items[layer]['UB'] = UB\n",
    "            \n",
    "    def compute_scalings(self):\n",
    "        \n",
    "        for layer, stored_values in self.stored_items.items():\n",
    "            UA = stored_values['UA']\n",
    "            UB = stored_values['UB']\n",
    "            h = stored_values['input']\n",
    "            delta = stored_values['grad_wrt_output']\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch_size = h.shape[1]\n",
    "                # TODO Check that this is correct\n",
    "                # Because delta and h contain information for each training example in the mini-batch,\n",
    "                # when we do the matrix multiplication in the middle, we are averaging over the mini-batch.\n",
    "                # So, we need to square the values first, so we can square-then-average, not average-then-square.\n",
    "                scalings = ((UB @ delta.t())**2) @ ((h.t() @ UA.t())**2) / batch_size\n",
    "                \n",
    "            stored_values['scalings'] = scalings\n",
    "            \n",
    "    def precondition(self):\n",
    "        for layer, stored_values in self.stored_items.items():\n",
    "            \n",
    "            UA = stored_values['UA']\n",
    "            UB = stored_values['UB']\n",
    "            \n",
    "            S = stored_values['scalings']\n",
    "            \n",
    "            grad_mb = layer.weight.grad.data # mb stands for 'mini-batch'\n",
    "            grad_mb_kfe = UB @ grad_mb @ UA.t()\n",
    "            grad_mb_kfe_scaled = grad_mb_kfe / (S + self.epsilon)\n",
    "            grad_mb_orig = UB.t() @ grad_mb @ UA # back to original basis \n",
    "            \n",
    "            layer.weight.grad.data = grad_mb_orig\n",
    "            \n",
    "    def approximate_Fisher_matrix(self):\n",
    "        \"\"\" For testing/debugging, compute the layer-wise approximation to the empirical Fisher matrix \n",
    "            to compare to the Fischer information matrix \"\"\"\n",
    "        for layer, stored_values in self.stored_items.items():\n",
    "            \n",
    "            UA = stored_values['UA'].numpy()\n",
    "            UB = stored_values['UB'].numpy()\n",
    "            S = np.diag(stored_values['scalings'].numpy().reshape(-1))\n",
    "            \n",
    "            UAkronUB = np.kron(UA, UB)\n",
    "            \n",
    "            approximate_Fisher = UAkronUB @ S @ UAkronUB.T\n",
    "            \n",
    "            stored_values['aproximate_Fisher'] = torch.tensor(approximate_Fisher)\n",
    "            \n",
    "    def empirical_Fisher_matrix(self):\n",
    "        \"\"\" For testing/debugging, compute the layer-wise empirical Fisher matrix\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 20, 2, 4, 1\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H, bias=False),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(H, D_out, bias=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "EKFAC_one = EKFAC(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mod = model(x)\n",
    "loss_fun = torch.nn.MSELoss(reduction='sum')\n",
    "z = loss_fun(y, y_mod)\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "EKFAC_one.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "EKFAC_one.approximate_Fisher_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Linear(in_features=2, out_features=4, bias=False): {'UA': tensor([[ 0.0079, -1.0000],\n",
       "          [-1.0000, -0.0079]]),\n",
       "  'UB': tensor([[ 0.6154,  0.1195,  0.5922, -0.5062],\n",
       "          [-0.7434,  0.1788,  0.2179, -0.6066],\n",
       "          [ 0.2571,  0.0379, -0.7714, -0.5809],\n",
       "          [ 0.0509,  0.9759, -0.0825,  0.1957]]),\n",
       "  'aproximate_Fisher': tensor([[ 6.5438e-03,  3.9935e-03, -1.1364e-03, -1.3127e-03, -1.7382e-05,\n",
       "            1.0569e-04, -3.7308e-05, -4.0096e-05],\n",
       "          [ 3.9935e-03,  5.0093e-03,  1.8776e-03, -1.2160e-03,  1.0569e-04,\n",
       "           -6.3187e-05,  4.6136e-05, -3.9526e-05],\n",
       "          [-1.1364e-03,  1.8776e-03,  9.3892e-03, -5.1357e-04, -3.7308e-05,\n",
       "            4.6136e-05,  6.1573e-05, -1.3984e-05],\n",
       "          [-1.3127e-03, -1.2160e-03, -5.1357e-04,  1.8439e-03, -4.0096e-05,\n",
       "           -3.9526e-05, -1.3984e-05, -1.8577e-04],\n",
       "          [-1.7382e-05,  1.0569e-04, -3.7308e-05, -4.0096e-05,  8.7404e-03,\n",
       "           -9.3623e-03,  3.5782e-03,  3.7543e-03],\n",
       "          [ 1.0569e-04, -6.3187e-05,  4.6136e-05, -3.9526e-05, -9.3623e-03,\n",
       "            1.2994e-02, -3.9527e-03,  3.7789e-03],\n",
       "          [-3.7308e-05,  4.6136e-05,  6.1573e-05, -1.3984e-05,  3.5782e-03,\n",
       "           -3.9527e-03,  1.6081e-03,  1.2536e-03],\n",
       "          [-4.0096e-05, -3.9526e-05, -1.3984e-05, -1.8577e-04,  3.7543e-03,\n",
       "            3.7789e-03,  1.2536e-03,  2.5320e-02]]),\n",
       "  'grad_wrt_output': tensor([[-0.0535, -0.0654, -0.0589,  0.0190],\n",
       "          [ 0.0141,  0.0254,  0.0423, -0.0146],\n",
       "          [-0.0602, -0.0708, -0.0565,  0.0208],\n",
       "          [-0.0583, -0.0726, -0.0719,  0.0217],\n",
       "          [ 0.0716,  0.0825,  0.0720, -0.0303],\n",
       "          [ 0.0882,  0.1021,  0.0767, -0.0303],\n",
       "          [-0.0861, -0.1033, -0.0920,  0.0305],\n",
       "          [ 0.1038,  0.1414,  0.1554, -0.0426],\n",
       "          [ 0.0635,  0.0741,  0.0702, -0.0238],\n",
       "          [ 0.0756,  0.0931,  0.0940, -0.0341],\n",
       "          [-0.0718, -0.0852, -0.0808,  0.0304],\n",
       "          [ 0.2704,  0.3221,  0.3201, -0.1017],\n",
       "          [-0.1363, -0.1615, -0.1593,  0.0513],\n",
       "          [ 0.1679,  0.1895,  0.1544, -0.0630],\n",
       "          [ 0.0422,  0.0582,  0.0606, -0.0164],\n",
       "          [ 0.0839,  0.1023,  0.1037, -0.0320],\n",
       "          [ 0.1050,  0.1228,  0.1176, -0.0392],\n",
       "          [ 0.1095,  0.1251,  0.1067, -0.0406],\n",
       "          [-0.0995, -0.1192, -0.1114,  0.0475],\n",
       "          [ 0.0494,  0.0752,  0.0950, -0.0235]]),\n",
       "  'input': tensor([[-0.1568, -3.8688,  0.6716, -0.3101,  1.6418,  0.8747, -0.2933, -0.9309,\n",
       "           -0.6818, -1.6505,  1.4701, -0.4935, -0.5375, -1.2063,  0.6417, -0.5638,\n",
       "           -0.5976, -0.9863,  2.0077, -1.5330],\n",
       "          [ 1.5009, -1.0266, -1.7695, -1.1190, -0.7852, -1.9219,  1.3996, -1.3532,\n",
       "            0.4409,  0.0608, -0.3746, -0.2079, -0.0530,  1.2508,  1.7413, -0.5565,\n",
       "            0.3512,  1.1028, -0.4757, -1.6048]]),\n",
       "  'scalings': tensor([[0.0219, 0.0265],\n",
       "          [0.0001, 0.0002],\n",
       "          [0.0011, 0.0014],\n",
       "          [0.0097, 0.0105]])},\n",
       " Linear(in_features=4, out_features=1, bias=False): {'UA': tensor([[ 0.6918,  0.2778, -0.3843,  0.5445],\n",
       "          [ 0.1900, -0.0510,  0.8895,  0.4125],\n",
       "          [-0.2157, -0.7963, -0.2374,  0.5128],\n",
       "          [-0.6624,  0.5348, -0.0690,  0.5200]]),\n",
       "  'UB': tensor([[1.]]),\n",
       "  'aproximate_Fisher': tensor([[ 0.9752,  0.0247, -0.6937, -0.2400],\n",
       "          [ 0.0247,  0.4302, -0.0277, -0.2513],\n",
       "          [-0.6937, -0.0277,  1.7043, -0.8224],\n",
       "          [-0.2400, -0.2513, -0.8224,  1.3730]]),\n",
       "  'grad_wrt_output': tensor([[ 0.9509],\n",
       "          [-1.1165],\n",
       "          [ 1.0349],\n",
       "          [ 1.0793],\n",
       "          [-1.4160],\n",
       "          [-1.5070],\n",
       "          [ 1.4990],\n",
       "          [-2.3056],\n",
       "          [-1.1050],\n",
       "          [-1.6606],\n",
       "          [ 1.4361],\n",
       "          [-4.7846],\n",
       "          [ 2.4003],\n",
       "          [-2.9487],\n",
       "          [-0.9151],\n",
       "          [-1.5409],\n",
       "          [-1.8209],\n",
       "          [-1.8981],\n",
       "          [ 2.2813],\n",
       "          [-1.4276]]),\n",
       "  'input': tensor([[0.3992, 0.9431, 0.5431, 0.6402, 0.3148, 0.5238, 0.4285, 0.7408, 0.5705,\n",
       "           0.7366, 0.3084, 0.5949, 0.5889, 0.5849, 0.2693, 0.6334, 0.5648, 0.5630,\n",
       "           0.2469, 0.8203],\n",
       "          [0.5231, 0.0906, 0.5413, 0.4232, 0.6967, 0.5651, 0.5008, 0.3344, 0.4179,\n",
       "           0.2842, 0.6866, 0.4247, 0.4232, 0.3706, 0.6392, 0.4049, 0.4268, 0.3957,\n",
       "           0.7456, 0.2577],\n",
       "          [0.6421, 0.8310, 0.2823, 0.4448, 0.2521, 0.2523, 0.6500, 0.5026, 0.6202,\n",
       "           0.7001, 0.2967, 0.5442, 0.5625, 0.7362, 0.5660, 0.5237, 0.6030, 0.7039,\n",
       "           0.2375, 0.5566],\n",
       "          [0.3653, 0.8136, 0.6265, 0.6293, 0.4648, 0.6275, 0.3836, 0.6886, 0.5032,\n",
       "           0.6060, 0.4362, 0.5544, 0.5422, 0.4591, 0.2957, 0.5929, 0.5063, 0.4587,\n",
       "           0.4099, 0.7425]], grad_fn=<TBackward>),\n",
       "  'scalings': tensor([[1.4280, 2.4969, 0.4464, 0.1114]])}}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EKFAC_one.stored_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 4\n",
    "x = torch.randn(dim, dim)\n",
    "symx = x @ x.t()\n",
    "\n",
    "evalsx, Ux = torch.symeig(symx, eigenvectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1789,  0.5882,  0.7885,  0.0173],\n",
       "        [-0.4364, -0.5153,  0.4953, -0.5465],\n",
       "        [-0.4592, -0.2305,  0.2582,  0.8181],\n",
       "        [-0.7528,  0.5791, -0.2573, -0.1782]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0006, -0.0015, -0.0016, -0.0027])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symx @ Ux[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0006, -0.0015, -0.0016, -0.0027])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalsx[0] * Ux[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3037,  0.8105,  0.6629, -0.3276],\n",
       "        [ 0.8105,  4.4579, -4.5959,  0.4143],\n",
       "        [ 0.6629, -4.5959,  7.9249, -2.0108],\n",
       "        [-0.3276,  0.4143, -2.0108,  0.9122]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ux @ torch.diag(evalsx) @ Ux.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3037,  0.8105,  0.6629, -0.3276],\n",
       "        [ 0.8105,  4.4579, -4.5959,  0.4143],\n",
       "        [ 0.6629, -4.5959,  7.9249, -2.0108],\n",
       "        [-0.3276,  0.4143, -2.0108,  0.9122]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
